[{"content":"I recently had the chance to start working with Apache Kafka as a part of a new module I\u0026rsquo;m working on at my workplace. So this is just me noting down my thoughts about my experience with Kafka as a series of articles.\nWhat is Apache Kafka? Apache Kafka is a popular distributed event processing or event streaming platform. Kafka contains three main capabilities under the hood, which we can use for our event streaming workloads. These capabilities are,\nAbility to publish (write) and subscribe (read) to event streams. Ability to store event streams reliably and durably for a configured amount of time. Ability to process events as they occur or retrospectively. Apart from that, what led to Kafka\u0026rsquo;s popularity was it\u0026rsquo;s highly-scalable, elastic, and fault-tolerant nature.\nIf you read up to this point, you would probably have the question of what the hell is Event Streaming in your head unless you have heard about it before. So let\u0026rsquo;s have a quick look into that before going any further.\nWhat is Event Streaming? To put it simply, think of a system continuously generating data. Each of these data points is considered an event, and when we capture those events as a continuous stream of events, it\u0026rsquo;s called an event stream.\nCapturing and storing these event streams durably for later retrieval; manipulating, processing, and reacting to the event streams in real-time as well as retrospectively; and routing the event streams to different destination technologies as required is known as event streaming.\nWhy Apache Kafka or Event Streaming/Processing So now we know what is Apache Kafka and what is Event Streaming/Processing is. Let\u0026rsquo;s now try to digest why do we need such things. We are all aware that purpose of most applications we develop is to recive some data, process them according given set of rules and provide a response or not. So let\u0026rsquo;s see how does Kafka fits into this.\nAs of today most of the applications we use rely on REST APIs for communication. REST provide us a way to talk to these applications over HTTP and it happens mostly in 3 steps. First a request is made and then the application processes that request. Then a response is sent back to the party which made the request and then they act upon the received response. This scenario works for most of the situations out there.\nBut think of an scenario where an application is producing 100s of events in a minute and we need these events to be processed by another application, or of a scenario where multiple applications are doing different actions based on a data received from another application. One key thing common to both scenarios is that data processing is not immediate and the system which ever is sending the data does not expect an immediate response from the downstream systems. So a usual REST based communication between systems won\u0026rsquo;t work for such scenarios since REST is all about synchronous request and response. And in first scenario it would be a pain to scale the application with growing number of events. So it\u0026rsquo;s clear that for cases like this we need a new way of doing thigs. This is where Kafka or in general event streaming and processing comes in. Kafka provides us a reliable location to write our data (events) and means for other applications to read and process these data asynchronously without having tight coupling between them.\nSo now we have an general idea about what is Kafka and why we need it. Let\u0026rsquo;s dive into more details about Kafka with the next article from this sereis. See you next time.\n","permalink":"https://isurubuddhika.dev/posts/apache-kafka-part-1/","summary":"I recently had the chance to start working with Apache Kafka as a part of a new module I\u0026rsquo;m working on at my workplace. So this is just me noting down my thoughts about my experience with Kafka as a series of articles.\nWhat is Apache Kafka? Apache Kafka is a popular distributed event processing or event streaming platform. Kafka contains three main capabilities under the hood, which we can use for our event streaming workloads.","title":"Apache Kafka Series : Introduction to Apache Kafka"},{"content":"Hi, I\u0026rsquo;m Isuru Buddhika Pathirana (He/Him), and I\u0026rsquo;m a Software Engineer.\nI primarily work with Java (Backend) but, I know my way around the complete stack.\nI used to hate React and love Angular but, now I love both equally. (maybe React a little bit more)\nYou might find me annoying if your code is not clean. I won\u0026rsquo;t accept your PRs unless those are clean and up to the standards.\nI occasionally write about my dev experiences, software engineering, open-source, and digital privacy. I\u0026rsquo;m more of a reader than a writer, so don\u0026rsquo;t expect frequent blogging. ðŸ˜‰\nYou can DM me on Twitter or contact me via hello\\at\\isurubuddhika\\dot\\me\n","permalink":"https://isurubuddhika.dev/about/","summary":"Hi, I\u0026rsquo;m Isuru Buddhika Pathirana (He/Him), and I\u0026rsquo;m a Software Engineer.\nI primarily work with Java (Backend) but, I know my way around the complete stack.\nI used to hate React and love Angular but, now I love both equally. (maybe React a little bit more)\nYou might find me annoying if your code is not clean. I won\u0026rsquo;t accept your PRs unless those are clean and up to the standards.","title":"About"},{"content":"I have always wanted to move away from wordpress and start writing my blogs in Markdown. Hell, I event thought of keeping the wordpress blog as it is and publish content off GitLab or GitHub to it.\nBut I always felt like it\u0026rsquo;s better to move on to a static site with my own domain. So finally I found the time to setup everything an get back on blogging again.\nLet\u0026rsquo;s see how would things turn out.\nYou can find my previous blog at https://d3vlogs.wordpress.com\n","permalink":"https://isurubuddhika.dev/posts/migrating-to-hugo/","summary":"I have always wanted to move away from wordpress and start writing my blogs in Markdown. Hell, I event thought of keeping the wordpress blog as it is and publish content off GitLab or GitHub to it.\nBut I always felt like it\u0026rsquo;s better to move on to a static site with my own domain. So finally I found the time to setup everything an get back on blogging again.","title":"Migrating to Hugo"}]